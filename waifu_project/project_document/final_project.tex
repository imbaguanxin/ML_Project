\documentclass[11.5pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{cite}



\title{Recognize Animation Characters with Machine Learning}

\author{Xin Guan, Ziqian Ge}

\date{}

\begin{document}

    \maketitle

    \abstract
    Please provide a brief abstract of your project.
    

    \vspace{2mm}


    \section{Introduction}
    As the fandom community of animation grows, a large number of fan-arts made by non-official illustrators began to show up and gradually became an significant part of the community.
    Fan-arts spread on the internet are often not labeled or are hard for people, especially those who are new to the community, to recognize the illustrating character, since many anime characters shares similar characteristics and different illustrators may shift some of the features base on their own taste. Therefore, one character may look very different under different painters and many characters may look alike.
    \begin{figure}[!ht]
        \begin{subfigure}[h]{0.5\linewidth}
            \centering
            \includegraphics[width=0.8\linewidth, scale=1]{./images/tosaka_grid.png}
            \caption{Same Character by different illustrators}
        \end{subfigure}
        \begin{subfigure}[h]{0.5\linewidth}
            \centering
            \includegraphics[width=0.8\linewidth, scale=1]{./images/saber_grid.png}
            \caption{Similar characters}
        \end{subfigure}
        \caption{Various Looks of a Single Character and Similar but different Characters}
    \end{figure}
    \\ \\
    Untagged illustrations would make some trouble for animation community members.
    Large number of 'Who is she/he' questions are emerging on social networks plantforms like Twitter, 2Chan and Bilibili.
    Even some video makers are making videos on answering those questions.
    On the other hand, within the machine learning community, if anyone is trying to make a illustration suggestion system based on the features or characteristics of anime characters, or trying to use GAN (Generative Adversarial Network) to generate fake anime illustrations, they might have to tag those pictures manually.\\ \\
    Automatic character recognizing would then make some differences when one is facing a large set of untagged illustrations or would like to add/optimize tags based on character, for example, a character may be bounded to specific tags, like blond, green-eye, sword, armored, etc.\\ \\
    This project is aiming to use machine learning techniques to automatically recognize characters in illustrations, based on their faces. We are mainly focusing on characters from japanese styled mangas and aminations. This project is making use of a variety of classification models including models like logistic regression classifier, random forest classifier and support vector machine and neural networks.\\ \\
    In order to make it possible to train non-neural-network models, we performed feature extraction techniques on images during the preprocessing stage. The first strategy is extracting the texture, color and shape of the image contents and then flattern those features to an vector for the models to lean. The second strategy is extracting features using the output of the last layer of pre-trained ResNet[] as the image features and train them on non-neural-network models.\\ \\
    In this project, we did hyperparameter tunning on a rather small dataset that is collected manually by us and then train the model on the whole dataset which consists of ours and Nagadomi's anime face character dataset[]. Neural network performed best with a recognition rate of 90\%. Support vector machine was the best model among non-neural-network models with ResNet extracted features. However, our first strategy leads to rather poor accuracy rate on all models (about 20\% accurate rate on 178 classes).


    \section{Technical Approach}
    % Please describe the techniques you have used in order to address the problem.
    % Describe in detail the classification/regression/other techniques you have used in order to tackle the problem.

    In this project, we made use of techniques relating to image feature extractions, classification models and neural networks to tackle the animation image classification problem.

    \begin{enumerate}
        \item \textbf{Feature Extraction Algorithms}
        
        Initially, we naively flatterned the RGB channels of a image to a vector as the input of the models, but find out that about 5-15 minutes are required to train a model even on the small dataset collected by ourselves. Additionaly, the prediction is not accurate since the flatterning process destroies the spacial relation between each pixels. Therefore, we find some way to extract the features of a image.
        \begin{itemize}
            \item \textbf{Image Moment}
            
            Image moment is a certain particular weighted average of the image pixels' intensities. A uniqueness theorem \cite{img_moment} claim that a piecewise continuous 2D function $f(x,y)$ with nonzero values in a finite part of the $xy$ plane, then moments of all orders exist and moment sequence is uniquely determined by $f(x,y)$. Image moments are useful to describe the shape of a image content. In this project, we made use of pre-implemented function $hu\_moment()$ in \textbf{OpenCV}\cite{opencv_library} to process the image.
            \item \textbf{Haralic Texture}
            
            Haralic texture, proposed by R. M. Haralick et al. in 1973, is describing a textural features "based on graytone spatial dependancies" \cite{haralick}. This algorithm is trying to conclude the texture of a surface and the "structural arrangement of surfaces and their relationship to the surrounding environment"[]. In this project, we made use of the algorithm to extract the texture information of the images. The extraction of Haralic Textures is implemented in python package \textbf{mahotas}\cite{mahotas}, with function $mahotas.features.haralick()$
            \item \textbf{Histogram of Colors}
            
            In order to zip the information of color of a image, we decide to calculate how color are ditributed in $HSV$ channels. To discretize the continuous distribution of colors, we decide to use 8 bins in each channel and thus store the histogram of colors to a vector. Again, we made use of \textbf{OpenCV}\cite{opencv_library} to process the image.
        \end{itemize}
        \item \textbf{Prediction Models}
        
        In this project, we made use of many of the models that we learned in this course as well as some models in the prerequisite of this course. The implementation of these models are from python package \textbf{scikit-learn}\cite{scikit-learn}. 
            \begin{itemize}
                \item \textbf{Logistic Regression}
                
                Logistic regression is used to model the probability of a certain class. With the feature input $x \in \mathbf{R}^n$, calculate $w^Tx + b, w \in \mathbf{R}^n, b \in \mathbf{R}$ the probability of $x$ in certain class is denoted by 
                $$p(x = X | w) = \frac{1}{1 + e^{-(w^Tx + b)}}$$
                In order to tacle overfitting problem, we also add a regularization strength $\lambda$:
                $$p(x = X | w) = \frac{1}{1 + e^{-(w^Tx + b)}} + \lambda ||w||^2_2$$
                where $||w||_2^2$ is the $l_2$-norm of $w$. $\lambda$ is a hyperparameter need to be determined before training. Training logistic regression is through gradient descent. \\ \\
                In \textbf{scikit-learn}\cite{scikit-learn}, this problem is formed as a optimization problem: 
                $$\min_{w, c} f(w) + c\sum_{i=1}^{n}\frac{1}{1 + e^{-y_i(w^Tx_i + b)}} $$ 
                where $f(w) = ||w||^2_2$ if we choose $l_2$ penalty.\\ \\
                In order to enable the model to classify multi-labels data, we train $k$ models for $k$ labels. Each model is a "one-vs-rest" classifier. When testing a given input, just find out the highest probability of all models and assign its class to the input.
                \item \textbf{Linear Discriminant Analysis}
                
                Linear discriminat analysis(LDA) is a Fisher's linear discriminant\cite{fisherDA}. It is closely related to analysis of variance (ANOVA) and regression analysis. LDA assumes that the conditional probability density functions are normally distributed and the class covariances are identical.           In this project, we uses multiclass LDA. This multiclass generalization is due to C. R. Rao\cite{multiLDA}. Also, we directly use the implemented model from \textbf{Scikit-learn}\cite{scikit-learn}

                \item \textbf{k-nearest neighbors}
                
                $k$-nearest neighbors(kNN) is a non-parametric passive model used for classification. Upon an input object, the model classify by a vote of its neighbors. The most often appeared class in its $k$ neareast neighbors are the output class. $k$ is a hyperparameter that we need to decide before the training.
                \item \textbf{Decision Trees}
                
                Decision Trees are a non-parametric supervised learning method used for classification. The model is in a tree structures where its leaves represent class labels and branches represent conjunctions of features that lead to those classes. In this project we directly use the Classification and Regression Tree (CART) implemented in \textbf{scikit-learn}\cite{scikit-learn}.
                \item \textbf{Random Forest}
                
                Random Forest is constructing a mutiple decisions trees at training time and outputting the class that is the mode of the classes of individual trees. This method is first proposed by Tin Kam Ho in 1995\cite{random_forest}. Training process, called bagging\cite{rf_bagging}, is repeatly select a random sample with replacement of the training set and fits a decision tree with these samples. We made use of the $RandomForestClassifier$ of \textbf{scikit-learn}\cite{scikit-learn} to perform the classification job.
                \item \textbf{Gaussian Naive Bayes}
                
                Naive Bayes is based on applying Bayes theorem with assumptions of features are mutually independent with each other. With Bayes rule, probability of a input vector $x$ being class $y_i$ is 
                $$P_{y_i}(x) = p(Y = y | X = [x_1, x_2, \dots] ) = \frac{p( X = [x_1, x_2, \dots] | Y = y)p(Y = y)}{p(X = [x_1, x_2, \dots])} $$
                where $Y$ is the class, $x_i$'s are different features. With naive bayes assumptions, $p(X = [x_1, x_2, \dots] | Y = y) = \prod_i p(X_i = x_i | Y = y)$. Therefore,
                $$P_{y_i}(x) \propto \prod_i p(X_i = x_i | Y = y)p(Y = y)$$
                In $N$ class classification, we can calculate the value of all $P_{y_i}(x)$ for $i \in 1,2 \dots N$ according to data set. Then, we find the largest $P_{y_i}(x)$ and assign $y_i$ to $x$.\\ \\
                Gaussian Naive Bayes is just making the assumption that the features are normally distributed. Given a dataset D with $L$ data entries:
                $$P(X_i = x_i | Y = y) = N(\mu_{x_i}, \sigma^2_{x_i})$$
                $$\mu_{x_i} = \frac{\sum_{k = 1}^L {X_k}_i}{L}$$
                $$\sigma_{x_i} = \frac{\sum_{k = 1}^L ({X_K}_i - \mu_{x_i})^2}{L}$$
                Where $N(\mu, \sigma)$ denotes normal distribution of mean $\mu$, standard deeviation $\sigma^2$.
                \item \textbf{Support Vector Machines}
                
                Support Vector Machines(SVMs) are supervised learning models used for regression and classification problems. With the assumption that the data is seperatable with a hyperplane, SVM is trying to find the hyperplane with the maximized margin between the data point in each class and the hyperplane.
                \begin{figure}[h!]
                    \centering
                    \includegraphics[width=0.3\linewidth]{./images/svm.png}
                    \caption{Maximum-margin hyperplane for a 2-class SVM}
                \end{figure}\cite{svm_pic}\\ \\
                We made use of the C-Support Vector Classification (SVC) provided by \textbf{scikit-learn}\cite{scikit-learn}. We selected the "one-vs-one" scheme during the training. Hyperparameters need selection: regularization parameter $C$, kernel funciton, and the degree of polynomial kernal(if polynomial function is selected as kernel). 
            \end{itemize}
        \item \textbf{Neural Networks}
        
        Neural Networks(NN), first introduced by Warren McCulloch and Walter Pitts\cite{nn_init} are computing structures inspired by biological neural networks. This system is composed of several layers of artifical neurons that mimics the firing of biological neurons. \\ \\
        In this project, we used \textbf{pytorch}\cite{pytorch} to form and train neural networks. Particularly, we borrowed the ResNet\cite{resnet} that is pre-trained on ImageNet \cite{imgnet} and added a layer of neurons representing our class labels and trained the net with our dataset.
    \end{enumerate}


    \section{Experimental Results}
%    Describe the datasets used for your experiments. Be precise in describing all information about the datasets, including, classes, number of samples per class, features used to represent data, and all pre/post processing of the datasets.\\
%    Describe the details about the implementation of each algorithm, e.g., how you perform training, validation, testing, values of the hyperparameters and your methods for hyperparameter tuning, training/validation/testing error on the dataset, and all useful plots/tables that help to better interpret your results and your work.\\ \\
    In this project, we have gone through following working pipeline.
    Firstly, we manually cleaned the Nagadomi's Anime Face Character Dataset and generated our own dataset with better image quality and modern animation characters.
    Then, we performed image pre-processing and feature extractions to generate three union of data: color-texture-shape information, ResNet-processed information and normalized RGB information.
    Then we designed different models according to these unions of data.
    According to our models, we did hyperparameter tuning on the self-collected dataset and then trained the model with the optimized hyperparameter on the whole dataset and evaluate the prediction result.
    Following are the detailed description of each step in the working pipeline.

    \begin{enumerate}
        \item \textbf{Dataset Overview}
        \begin{itemize}
            \item \textbf{Nagadomi's Anime Face Character Dataset}

            Nagadomi's dataset contains a lot of falsely labeled images, some differently labeled images that are actually the same character, a lot of images that cannot be recognized even by human, and a lot of characters does not contain sufficient amount of data, i.e.\ some characters has less than 100 images.
            Bad images like ones shown below were removed from our dataset manually and a copy of filtered data is stored separately.\\ \\
            \begin{figure}[h!]
                \begin{subfigure}[h]{0.5\linewidth}
                    \centering
                    \includegraphics[width=0.5\linewidth, scale=0.5]{images/face_145_303_113.png}
                    \caption{Bad Nagato Yuki}
                \end{subfigure}
                \begin{subfigure}[h]{0.5\linewidth}
                    \centering
                    \includegraphics[width=0.5\linewidth, scale=0.5]{images/face_235_235_128.png}
                    \caption{Good Nagato Yuki}
                \end{subfigure}
                \caption{Comparison between a bad image and a good image}
            \end{figure}
            \begin{figure}[h!]
                \begin{subfigure}[h]{0.5\linewidth}
                    \centering
                    \includegraphics[width=0.5\linewidth, scale=0.5]{images/face_795_301_69.png}
                    \caption{Meirin Ri labeled as Daidouji Tomoyo}
                \end{subfigure}
                \begin{subfigure}[h]{0.5\linewidth}
                    \centering
                    \includegraphics[width=0.5\linewidth, scale=0.5]{images/face_1141_433_41.png}
                    \caption{Real Daidouji Tomoyo}
                \end{subfigure}
                \caption{The character on the left, Meirin Ri is falsely labeled as Daidouji Tomoyo}
            \end{figure}
            \item \textbf{Self-collected Dataset}

            We have also collected some images for about 10 characters, each with over 100 images, manually from animations and illustrations published on web.
            These images are basically in the same format as images in Nagadomi's dataset, square-like images of faces of anime characters.
            \item \textbf{Subset-ing the whole dataset}

            There are a total of 173 characters, and it was impracticable to train our models and tune hyperparameters using all of our data due to lack of computing power and time.
            We decide to manually pick some characters from the whole dataset, each with over 100 images, to make subset of the total dataset to tune hyper-parameters.
            The training and testing on the whole dataset was be performed using the hyperparameter tuned from that subset and the results will be reported.
        \end{itemize}
        \item \textbf{Non-Neural-Network Models}
        \begin{itemize}
            \item \textbf{Data Pre-processing and Feature Extraction}

            This feature extraction process was a direct combination of HuMoments (implemented in OpenCV), Haralick features (implemented in mahotas), and color histogram (implemented in OpenCV).
            The result of the previous feature extraction was plugged as input into the next feature extraction method.
            The order of feature extraction we chose was: HuMoments $\rightarrow$ Haralick $\rightarrow$ color histogram.
            \item \textbf{Model implementation}

            We have trained logistic regression classifier, K neighbors classifier, decision tree classifier, random forest classifier, Gaussian Naive Bayes classifier, and support vector machine classifier all using \texttt{scikit-learn} to tune hyper-parameters on the subset described above.
            \item \textbf{Hyperparameter Tunning}
            Hyperparameters was tuned using the subset of dataset described above and the result using all of our data would also be produced after hyperparameters was tuned.
            \begin{enumerate}
                \item Logistic Regression classifier

                Since we chose to use "lbfgs" solver in scikit-learn, we can only use l2-norm in penalization, or use no regularization.
                Logistic regression models with or without regularization functions and with different regularization strength used in penalty function (C in scikit-learn) was trained to find out whether we are regularizing and the value of regularization strength.
                The regularization strength, C, was tested with floats ranging from $0.1$ to $10.0$ to find the best value.

                Testing results:

                \begin{figure}[h!]
                    \begin{subfigure}[b]{0.5\linewidth}
                        \centering
                        \includegraphics[width=\linewidth]{images/log_reg_hyperparam_penalty.png}
                    \end{subfigure}
                    \begin{subfigure}[b]{0.5\linewidth}
                        \centering
                        \includegraphics[width=\linewidth]{images/log_reg_hyperparam_c.png}
                    \end{subfigure}
                    \caption{Logistic Regression classifiers hyperparameter tuning}
                \end{figure}





                As shown in the result, we should have l2-norm regularization in penalty function.

                \item K Neighbors classifier

                We tried out different values of $k$, ranging from $2$ to $30$ to find the best value of $k$.

                Testing results:

                \includegraphics[width=0.75\linewidth]{images/knn_k.png}

                \item Random Forest classifier

                We have tried forests with different loss function, Gini impurity function and Information Entropy function, both accuracy and computing time was record:

                \begin{figure}[h!]
                    \begin{subfigure}[b]{0.5\linewidth}
                        \centering
                        \includegraphics[width=\linewidth]{images/rand_forest_loss_func.png}
                    \end{subfigure}
                    \begin{subfigure}[b]{0.5\linewidth}
                        \centering
                        \includegraphics[width=\linewidth]{images/rand_forest_n_estimators.png}
                    \end{subfigure}
                \end{figure}

                As shown in the graph, we should use Gini impurity function as our loss function and the best number of estimators is $1200$.

                \item Support Vector Machine classifier

                We have tried different kernels, linear, polynomial, rbf, and sigmoid kernels to find the best kernel among them.

                \includegraphics[width=0.75\linewidth]{images/svm_kernel.png}

                For polynomial kernel, we have also tried and tested different degree of polynomial kernel, ranging from $1$ to $20$, to find the best degree.
                The regularization strength, C, was also tested with floats ranging from $1$ to $30.0$ to find the best value.

                \includegraphics[width=\linewidth]{images/svm_c_degree.png}

                The best hyperparameter $C = 4.0$ and $degree = 4$, with accuracy $= 0.799$

                \begin{figure}

                \end{figure}

            \end{enumerate}
            \item \textbf{Prediction Result}
        \end{itemize}
        \item \textbf{Neural-Network Model}
        \begin{itemize}
            \item \textbf{Data Pre-processing}
            \item \textbf{Hyperparameter}
            \item \textbf{Prediction Result}
        \end{itemize}
    \end{enumerate}
    For traditional models approach, we have trained logistic regression classifier, K neighbors classifier, decision tree classifier, random forest classifier, Gaussian Naive Bayes classifier, and support vector machine classifier using \texttt{scikit-learn} to tune hyper-parameters on the subset described above.
    The classification result using all of our data was produced using the model performing the best in the subset after all hyper-parameter was tuned.\\ \\
    For neural networks approach, we chose ResNet, which was implemented in \texttt{PyTorch}, to be our neural network model.
    We have trained ResNets with different number of layers, 18 layers (ResNet18), 34 layers (ResNet34), 50 layers (ResNet50), 101 layers (ResNet 101) on the same subset that was used in hyper-parameter tuning process of traditional models to find the network with number of layers performing the best.
    The classification result using all of our data was also produced using the network performing the best in the subset.\\ \\
    For the combination of traditional models and neural network approach, we decided to train traditional models using the results from the neural network that was chosen in the neural networks approach, so that the ResNet would work as a feature extraction method for traditional models.
%    \\ \\
    For tuning support vector machine classifier, we \\ \\
    The same process of hyper-parameter tuning was also performed in the ResNet-traditional combined approach, as the best values in different approaches are not guaranteed to be the same.


    \section{Participants Contribution}
    Please list the name of the participants. For each participant explain in details the role he/she played in the project: explain which methods was implemented by which member, which dataset was processed by which member, which experimental results were generated by which members, etc.

    \vspace{10mm}
    ** Please do not change the size of the fonts.

    ** Please note that your submission must be at most 7 pages long, excluding references.

    \newpage
    \bibliographystyle{acm}
    \bibliography{ref}{}
    

    
\end{document}
